{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CORELLA_Github.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubb5PIs3LCRV",
        "colab_type": "text"
      },
      "source": [
        "# Corella: A Private Multi Server Learning Approach based on Correlated Queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyIeJG8wLhB_",
        "colab_type": "text"
      },
      "source": [
        "## Read Me!\n",
        "\n",
        "This code is provided in a Jupyter notebook file.\n",
        "\n",
        "Prerequisites: Python 3.6+  ||  PyTorch 1.0+ || NumPy\n",
        "\n",
        "Our system device: cuda\n",
        "\n",
        "## -------------------------- Input --------------------------\n",
        "\n",
        "---- Input: DatasetName, [arg1,arg2], $\\sigma_{\\bar{Z}}^*$, $\\mathrm{W}$\n",
        "\n",
        "---- Default example: MNIST [Iden,Iden] 70 [[1.0,-1.0]]\n",
        "\n",
        "### details:\n",
        "\n",
        "---- DatasetName: (MNIST, Fashion-MNIST, and Cifar-10)\n",
        "\n",
        "Note: We use their standard training set and test set. We set the training batch size equal to 128. The only used preprocessing on the images is Random Crop and Random Horizontal Flip on Cifar10 dataset.\n",
        "\n",
        "---- [arg1,arg2]: (The network structure) arg1: (Iden, 1, 2, ...) ----->  arg2: (Iden, 10, 11, ...)\n",
        "\n",
        "Note:  We initialize the network parameters by PyTorch default.\n",
        "\n",
        "---- $\\sigma_{\\bar{Z}}^*$\n",
        "\n",
        "Note: To evaluate the accuracy of the proposed algorithm for a ﬁxed noise standard deviation, $\\sigma_{\\bar{Z}}^*$, we start training the model from $\\sigma_{\\bar{Z}}$ = 0 and gradually increase the noise standard deviation with linearly increasing step-size up to $\\sigma_{\\bar{Z}}$ = $\\sigma_{\\bar{Z}}^*$, where in each step we run one epoch of learning, and the ﬁnally we report the accuracy at $\\sigma_{\\bar{Z}}$ = $\\sigma_{\\bar{Z}}^*$. The sequence of step-sizes are linearly increases, as 0.002,0.004,0.006,... . We also decrease the learning rate from $10^{−3}$ to $2×10^{-5}$ during the training gradually.\n",
        "\n",
        "Note that in this paper, we concern about the privacy of the client data, and not the training samples.\n",
        "\n",
        "---- $\\mathrm{W}$: (a matrix with $T$ (the number of colluding servers) rows and $N$ (the number of servers) columns for creating $\\mathbb{P}_{\\mathbf{Z}}$)\n",
        "\n",
        "### -------------------------- Output --------------------------\n",
        "\n",
        "Reporting training accuracy during each learning epoch and testing accuracy at the end of each epoch for $\\sigma_{\\bar{Z}}$s.\n",
        "\n",
        "Note: If arg1=Iden, you can ignore $\\bar{g}_0()$ and $\\textsf{Normalized}()$ function, where the dataset is $\\textsf{Normalized}$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG3aZy-1KULm",
        "colab_type": "text"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYHVVwg5KTNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets\n",
        "import numpy as np\n",
        "\n",
        "# device\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print ('Your system: ' + str(device))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amBcI9dyAOso",
        "colab_type": "text"
      },
      "source": [
        "# Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCKT4mx7FOEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -------------- Custom examples -------------- #\n",
        "'''\n",
        "MNIST [Iden,32] 70 [[1.0,-1.0]]\n",
        "MNIST [Iden,Iden] 70 [[1.0,-1.0,10000.0]]\n",
        "MNIST [Iden,Iden] 70 [[1]]\n",
        "MNIST [Iden,32] 70 [[0.0,np.sqrt(3)/2,-np.sqrt(3)/2],[1.0,-1/2,-1/2]]\n",
        "Fashion-MNIST [Iden,32] 70 [[1.0,-1.0]]\n",
        "Cifar-10 [32,Iden] 70 [[1.0,-1.0]]\n",
        "Cifar-10 [32,128] 70 [[1,-1,10000,1.5,-1.5]]\n",
        "  .\n",
        "  .\n",
        "  .\n",
        "'''\n",
        "\n",
        "# input\n",
        "q = input('Default(d) or Custom(c) input? ')\n",
        "if q == 'c' :\n",
        "    DN,NS,Sigma,W = input('Input? ').split()\n",
        "else:\n",
        "    DN,NS,Sigma,W = 'MNIST', '[Iden,Iden]', '70', '[[1.0,-1.0]]'\n",
        "\n",
        "# type fixing\n",
        "if not(DN == 'MNIST' or DN == 'Fashion-MNIST' or DN == 'Cifar-10'):\n",
        "    print ('DatasetName is false; MNIST selected as the default.')\n",
        "    DN = 'MNIST'\n",
        "NS = list(map(str, NS[1:-1].strip().split(',')))[:2]\n",
        "Sigma = float(Sigma)\n",
        "exec('W = ' + W)\n",
        "W = np.array(W,dtype=float)\n",
        "N = len(W[0,:])\n",
        "T = len(W[:,0])\n",
        "IW = np.ones((N,T+1),dtype=float) \n",
        "IW[:,1:] = W.transpose()\n",
        "\n",
        "print(DN,NS,Sigma)\n",
        "print ('N = \\n {}'.format(N))\n",
        "print ('T = \\n {}'.format(T))\n",
        "print ('[1,W^T] = \\n {}:'.format(IW))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHeJnQC3KjCN",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op1hJmEsKIBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if DN == 'MNIST' :\n",
        "    # ------------ MNIST ------------ #\n",
        "    meanI = torch.tensor([0.1307])\n",
        "    stdI = torch.tensor([0.3040])\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = meanI, std = stdI),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = meanI, std = stdI),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "elif DN == 'Fashion-MNIST':\n",
        "    # ------------ Fashion-MNIST ------------ #\n",
        "    meanI = torch.tensor([0.2860])\n",
        "    stdI = torch.tensor([0.3205])\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = meanI, std = stdI),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = meanI, std = stdI),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "elif DN == 'Cifar-10':\n",
        "    # ------------ Cifar-10 ------------ #\n",
        "    meanI = torch.tensor([0.4914, 0.4822, 0.4465])\n",
        "    stdI = torch.tensor([0.2023, 0.1994, 0.2010])\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = meanI, std = stdI),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = meanI, std = stdI),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ40Vz5FREq8",
        "colab_type": "text"
      },
      "source": [
        "# Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4YJGM-vBBrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "isRGB = int(DN=='Cifar-10') # MNIST and Fashion-MNIST: 0   # Cifar-10: 1\n",
        "\n",
        "if NS[1]=='Iden':\n",
        "    NS1 = 10\n",
        "else:\n",
        "    NS1 = int(NS[1])\n",
        "\n",
        "# ---------------- \\bar{g}_0 ---------------- #\n",
        "if NS[0] == 'Iden':\n",
        "    class g_0(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(g_0, self).__init__()\n",
        "\n",
        "        def forward(self, X):\n",
        "            out = X\n",
        "            return out\n",
        "\n",
        "else:\n",
        "    class g_0(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(g_0, self).__init__()\n",
        "            self.client_L1_pad = nn.ConstantPad2d(( 1-isRGB, 0, 1-isRGB, 0),0)\n",
        "            self.client_L2_conv2d = nn.Conv2d( 1+2*isRGB, int(NS[0]), kernel_size=5, stride=3, padding=0)\n",
        "\n",
        "        def forward(self, X):\n",
        "            out = self.client_L1_pad(X)\n",
        "            out = self.client_L2_conv2d(out)\n",
        "            out = F.relu(out)\n",
        "            return out\n",
        "\n",
        "# ---------------- f_j ---------------- #\n",
        "if NS[0] == 'Iden':\n",
        "    class f_j(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(f_j, self).__init__()\n",
        "            self.server_L1_pad = nn.ConstantPad2d(( 1-isRGB, 0, 1-isRGB, 0),0)\n",
        "            self.server_L2_conv2d = nn.Conv2d( 1+2*isRGB, 64, kernel_size=5, stride=3, padding=0)\n",
        "            self.server_L3_conv2d = nn.Conv2d( 64, 128, kernel_size=3, stride=1, padding=0)\n",
        "            self.server_L4_fc = nn.Linear(128 * (7+isRGB) * (7+isRGB), 1024)\n",
        "            self.server_L5_fc = nn.Linear(1024, NS1)\n",
        "\n",
        "        def forward(self, X):\n",
        "            out = self.server_L1_pad(X)\n",
        "            out = self.server_L2_conv2d(out)\n",
        "            out = F.relu(out)\n",
        "            out = self.server_L3_conv2d(out)\n",
        "            out = F.relu(out)\n",
        "            out = out.reshape(out.size(0), -1)\n",
        "            out = self.server_L4_fc(out)\n",
        "            out = F.relu(out)\n",
        "            out = self.server_L5_fc(out)\n",
        "            return out\n",
        "\n",
        "else:\n",
        "    class f_j(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(f_j, self).__init__()\n",
        "            self.server_L1_conv2d = nn.Conv2d( int(NS[0]), 128, kernel_size=3, stride=1, padding=0)\n",
        "            self.server_L2_fc = nn.Linear(128 * (7+isRGB) * (7+isRGB), 1024)\n",
        "            self.server_L3_fc = nn.Linear(1024, NS1)\n",
        "\n",
        "        def forward(self, X):\n",
        "            out = self.server_L1_conv2d(X)\n",
        "            out = F.relu(out)\n",
        "            out = out.reshape(out.size(0), -1)\n",
        "            out = self.server_L2_fc(out)\n",
        "            out = F.relu(out)\n",
        "            out = self.server_L3_fc(out)\n",
        "            return out\n",
        "\n",
        "# ---------------- \\bar{g}_1 ---------------- #\n",
        "if NS[1] == 'Iden':\n",
        "    class g_1(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(g_1, self).__init__()\n",
        "\n",
        "        def forward(self, X):\n",
        "            out = X\n",
        "            return out\n",
        "\n",
        "else:\n",
        "    class g_1(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(g_1, self).__init__()\n",
        "            self.client_L2_fc = nn.Linear(NS1, 10)\n",
        "\n",
        "        def forward(self, X):\n",
        "            out = F.relu(X)\n",
        "            out = self.client_L2_fc(out)\n",
        "            return out\n",
        "\n",
        "# ---------------- network ---------------- #\n",
        "class network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(network, self).__init__()\n",
        "        # client\n",
        "        self.client_g_0 = g_0()\n",
        "        # servers\n",
        "        for j in range(N):\n",
        "            exec('self.server{} = f_j()'.format(j+1))\n",
        "        # client\n",
        "        self.client_g_1 = g_1()\n",
        "\n",
        "    def forward(self, X,Z_scale):\n",
        "        # \\bar{g}_0\n",
        "        U = self.client_g_0(X)\n",
        "        # normalize\n",
        "        U = U - torch.mean(U,[1,2,3],keepdim=True) * torch.ones(U.size()).to(device) # zero mean\n",
        "        U = U / torch.std(U,[1,2,3],keepdim=True) * torch.ones(U.size()).to(device) # set variance to 1\n",
        "        # add noise (queries)\n",
        "        Q = []\n",
        "        Z = (Z_scale * torch.randn( list(U.size())+[T] )).to(device) # primary noise\n",
        "        for j in range(N):\n",
        "            q = U * IW[j,0]\n",
        "            for t in range(T):\n",
        "                q += Z[:,:,:,:,t] * IW[j,t+1]\n",
        "            normP = torch.sqrt(torch.tensor(  IW[j,0]**2  + sum((Z_scale*IW[j,1:])**2)  )).to(device) # for normalizing the queries\n",
        "            Q += [ q / normP ]\n",
        "        # answers\n",
        "        A = []\n",
        "        for j in range(N):\n",
        "            exec('A += [self.server{}(Q[{}])]'.format(j+1,j))\n",
        "        # sumA\n",
        "        sumA = A[0]\n",
        "        for j in range(1,N):\n",
        "            sumA += A[j]\n",
        "        # out\n",
        "        out = self.client_g_1(sumA)\n",
        "        return out\n",
        "\n",
        "# ---------------- model ---------------- #\n",
        "model = network().to(device)\n",
        "if device == 'cuda':\n",
        "    model = torch.nn.DataParallel(model)\n",
        "    cudnn.benchmark = True\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwHv6Xnej6-J",
        "colab_type": "text"
      },
      "source": [
        "# Training and Evaluating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl1Q3sWUHIQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# variables storing \n",
        "Train_store = {\"Acc\":[], \"Loss\":[]}\n",
        "Test_store = {\"Acc\":[], \"Loss\":[]}\n",
        "ZL_store = {\"ZR\":[], \"LR\":[]}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfZsMe9ll9DU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss Function\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4z3xISJmHYY",
        "colab_type": "text"
      },
      "source": [
        "### Training code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoHTuwtKHrda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model():\n",
        "    loss_sum = 0\n",
        "    correct_sum = 0\n",
        "    sample_num = 0\n",
        "\n",
        "    model.train()\n",
        "    for (Step_images, Step_labels) in trainloader:\n",
        "        # data\n",
        "        images, labels = Step_images.to(device), Step_labels.to(device)\n",
        "        # forward\n",
        "        outputs = model(images,ZR)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # track\n",
        "        sample_num += labels.size(0)\n",
        "        loss_sum += (criterion(outputs, labels).item()) * labels.size(0)\n",
        "        correct_sum += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "\n",
        "    # print\n",
        "    print('NewEpoch: [{}/{}] '.format(epoch_num+1,TotalEpochs), end=' ')\n",
        "    print('NoiseScale: {:.3f} LearningRate: {:.2e}'.format(ZR,LR), end=' ')\n",
        "    print('Loss:',end=' ')\n",
        "    print('{:.4f}'.format(float(loss_sum)/float(sample_num)), end=' ')\n",
        "    print('Acc:',end=' ')\n",
        "    print('{:.2f}'.format(float(correct_sum)/float(sample_num)*100), end=' ')\n",
        "    print('')\n",
        "\n",
        "    # store\n",
        "    Train_store[\"Loss\"].append(float(loss_sum)/float(sample_num))\n",
        "    Train_store[\"Acc\"].append(float(correct_sum)/float(sample_num)*100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Saq7UGQjnsaZ",
        "colab_type": "text"
      },
      "source": [
        "### Test code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSq_AE2zZ9tL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model():\n",
        "    loss_sum = 0\n",
        "    correct_sum = 0\n",
        "    sample_num = 0\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (Step_images, Step_labels) in testloader:\n",
        "            # data\n",
        "            images, labels = Step_images.to(device), Step_labels.to(device)\n",
        "            # forward\n",
        "            outputs = model(images,ZR)\n",
        "            # track\n",
        "            sample_num += labels.size(0)\n",
        "            loss_sum += (criterion(outputs, labels).item()) * labels.size(0)\n",
        "            correct_sum += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "\n",
        "    # print\n",
        "    print('Test on {} images'.format(sample_num), end=' ')\n",
        "    print('NoiseScale: {:.3f}'.format(ZR), end=' ')\n",
        "    print('Loss:',end=' ')\n",
        "    print('{:.4f}'.format(float(loss_sum)/float(sample_num)), end=' ')\n",
        "    print('Acc:',end=' ') \n",
        "    print('{:.2f}'.format(float(correct_sum)/float(sample_num)*100), end=' ')  \n",
        "    print('')\n",
        "    print('')\n",
        "\n",
        "    # store\n",
        "    Test_store[\"Loss\"].append(float(loss_sum)/float(sample_num))\n",
        "    Test_store[\"Acc\"].append(float(correct_sum)/float(sample_num)*100)\n",
        "    ZL_store[\"ZR\"].append(ZR)\n",
        "    ZL_store[\"LR\"].append(LR)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIlTW0jLsyYz",
        "colab_type": "text"
      },
      "source": [
        "### Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD5FAWMqsxMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# total epochs\n",
        "TotalEpochs = int(np.ceil((-1+np.sqrt(1+8/0.002*Sigma))/2)) # solving [0.002 * (n * (n + 1) / 2) = Sigma]\n",
        "# learning rates\n",
        "LRs = np.logspace(np.log10(1e-3), np.log10(2e-5), num=TotalEpochs)\n",
        "# noise scale\n",
        "step_size = 0\n",
        "ZR = 0\n",
        "\n",
        "for epoch_num in range(TotalEpochs):\n",
        "    # noise scale\n",
        "    step_size += 0.002\n",
        "    ZR += step_size\n",
        "    # learning rate\n",
        "    LR = LRs[epoch_num]\n",
        "    # optimizer\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "    # train\n",
        "    train_model()\n",
        "    # test\n",
        "    test_model()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}